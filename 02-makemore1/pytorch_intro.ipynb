{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c967b191",
   "metadata": {},
   "source": [
    "# üöÄ PyTorch Intro\n",
    "\n",
    "Broadcasting is one of PyTorch's most powerful features - it lets you do operations between tensors of different shapes automatically. Let's explore this step by step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d10c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bf3d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27, 27), dtype=torch.int32)\n",
    "# Let's examine our tensor N\n",
    "print(\"Our tensor N:\")\n",
    "print(f\"Shape: {N.shape}\")        # Dimensions of the tensor\n",
    "print(f\"Data type: {N.dtype}\")    # What type of numbers it stores\n",
    "print(f\"Device: {N.device}\")      # CPU vs GPU\n",
    "print(f\"Total elements: {N.numel()}\")  # Total number of elements\n",
    "\n",
    "# Let's see what it looks like (first 5 rows and columns)\n",
    "print(\"\\nFirst 5x5 portion of N:\")\n",
    "print(N[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760eb33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create different types of tensors to understand the basics\n",
    "print(\"=== Creating Different Tensors ===\")\n",
    "\n",
    "# 1. Different ways to make tensors\n",
    "zeros = torch.zeros(3, 4)           # 3x4 matrix of zeros\n",
    "ones = torch.ones(2, 3)             # 2x3 matrix of ones  \n",
    "random = torch.randn(2, 2)          # 2x2 random normal distribution\n",
    "from_list = torch.tensor([1, 2, 3, 4])\n",
    "from_2dlist = torch.tensor([[1, 2], [1, 2]])  # From Python list\n",
    "\n",
    "print(\"Zeros (3x4):\")\n",
    "print(zeros)\n",
    "print(\"\\nOnes (2x3):\")  \n",
    "print(ones)\n",
    "print(\"\\nRandom (2x2):\")\n",
    "print(random)\n",
    "print(\"\\nFrom list:\")\n",
    "print(from_list)\n",
    "print(\"\\nFrom 2D list:\")\n",
    "print(from_2dlist)\n",
    "print(\"Shape:\", from_2dlist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ce3d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's play with indexing and slicing (like numpy arrays)\n",
    "print(\"=== Indexing and Slicing ===\")\n",
    "\n",
    "# Create a small tensor to experiment with\n",
    "small = torch.arange(12).reshape(3, 4)  # Numbers 0-11 in 3x4 shape\n",
    "print(\"Our test tensor:\")\n",
    "print(small)\n",
    "\n",
    "# Indexing examples\n",
    "print(f\"\\nElement at [1,2]: {small[1, 2]}\")           # Single element\n",
    "print(f\"First row: {small[0, :]}\")                    # Entire first row  \n",
    "print(f\"Second column: {small[:, 1]}\")                # Entire second column\n",
    "print(f\"Top-left 2x2: \\n{small[:2, :2]}\")           # 2x2 submatrix\n",
    "\n",
    "# You can also modify parts of tensors\n",
    "small[0, 0] = 999\n",
    "print(f\"\\nAfter changing [0,0] to 999:\")\n",
    "print(small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125f2d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic tensor operations\n",
    "print(\"=== Basic Tensor Operations ===\")\n",
    "\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "\n",
    "print(\"a =\", a)\n",
    "print(\"b =\", b)\n",
    "\n",
    "# Element-wise operations\n",
    "print(f\"\\na + b = {a + b}\")           # Addition\n",
    "print(f\"a * b = {a * b}\")             # Element-wise multiplication  \n",
    "print(f\"a ** 2 = {a ** 2}\")           # Squaring\n",
    "\n",
    "# Matrix operations\n",
    "matrix1 = torch.tensor([[1, 2], [3, 4]], dtype=torch.float)\n",
    "matrix2 = torch.tensor([[5, 6], [7, 8]], dtype=torch.float)\n",
    "\n",
    "print(f\"\\nMatrix multiplication:\")\n",
    "print(f\"matrix1 @ matrix2 = \\n{matrix1 @ matrix2}\")\n",
    "\n",
    "# Useful tensor methods\n",
    "print(f\"\\nUseful operations:\")\n",
    "print(f\"Sum: {a.sum()}\")\n",
    "print(f\"Mean of matrix1: {matrix1.mean()}\")\n",
    "print(f\"Max of a: {a.max()}\")\n",
    "print(f\"Shape of matrix1: {matrix1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f54669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's understand what your N tensor is for!\n",
    "print(\"=== Understanding the N tensor in context ===\")\n",
    "\n",
    "# Your N is a 27x27 matrix. Why 27? Let's figure it out!\n",
    "# It's probably for the 26 letters + 1 special character (like '.')\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "print(f\"Alphabet has {len(alphabet)} letters\")\n",
    "print(f\"With the '.' character, that's {len(alphabet) + 1} = 27 total\")\n",
    "\n",
    "# Let's create a mapping\n",
    "chars = ['.'] + list(alphabet) \n",
    "print(f\"Our character set: {chars}\")\n",
    "print(f\"Total characters: {len(chars)}\")\n",
    "\n",
    "# Create char to index mapping\n",
    "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "print(f\"\\nChar to index examples:\")\n",
    "print(f\"'.' -> {char_to_idx['.']}\")\n",
    "print(f\"'a' -> {char_to_idx['a']}\")  \n",
    "print(f\"'z' -> {char_to_idx['z']}\")\n",
    "\n",
    "print(f\"\\nSo N[i,j] will count how often character i is followed by character j!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdc79d7",
   "metadata": {},
   "source": [
    "## üéÆ Your Turn to Experiment!\n",
    "\n",
    "Try running each cell above to see how tensors work. Here are some fun experiments you can try:\n",
    "\n",
    "1. **Modify the tensors**: Change the numbers in the tensor creation cells\n",
    "2. **Try different operations**: Add `.transpose()`, `.reshape()`, or `.view()` to existing tensors  \n",
    "3. **Experiment with indexing**: Try `N[0:5, 10:15]` to see different parts of your N matrix\n",
    "4. **Check data types**: Try `torch.zeros((3,3), dtype=torch.float64)` vs `torch.int8`\n",
    "\n",
    "The next cell is a playground for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eaf2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ PLAYGROUND - Experiment here!\n",
    "# Try anything you want with tensors\n",
    "\n",
    "# Example experiments you can try:\n",
    "# 1. Create your own tensor\n",
    "my_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"My tensor:\", my_tensor)\n",
    "\n",
    "# 2. Try some operations\n",
    "print(\"Shape:\", my_tensor.shape)\n",
    "print(\"Transposed:\", my_tensor.T)\n",
    "\n",
    "# Your experiments below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c17d240",
   "metadata": {},
   "source": [
    "# üöÄ PyTorch Broadcasting Deep Dive\n",
    "\n",
    "Broadcasting is one of PyTorch's most powerful features - it lets you do operations between tensors of different shapes automatically. Let's explore this step by step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c48d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with the basic broadcasting rules\n",
    "print(\"=== Broadcasting Rule 1: Same-size tensors ===\")\n",
    "\n",
    "# Same shapes always work\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "print(f\"a: {a} (shape: {a.shape})\")\n",
    "print(f\"b: {b} (shape: {b.shape})\")\n",
    "print(f\"a + b = {a + b}\")\n",
    "print()\n",
    "\n",
    "print(\"=== Broadcasting Rule 2: Scalar with tensor ===\")\n",
    "# Scalar broadcasts to match any tensor shape\n",
    "scalar = 10\n",
    "tensor = torch.tensor([[1, 2], [3, 4]])\n",
    "print(f\"scalar: {scalar}\")\n",
    "print(f\"tensor: \\n{tensor} (shape: {tensor.shape})\")\n",
    "print(f\"scalar + tensor = \\n{scalar + tensor}\")\n",
    "print(\"The scalar 10 gets added to EVERY element!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2542d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The magic: Different shapes that broadcast together\n",
    "print(\"=== Broadcasting Rule 3: Compatible different shapes ===\")\n",
    "\n",
    "# Let's explore dimension compatibility\n",
    "matrix = torch.tensor([[1, 2, 3], \n",
    "                       [4, 5, 6]])  # Shape: (2, 3)\n",
    "\n",
    "row_vector = torch.tensor([10, 20, 30])  # Shape: (3,) \n",
    "col_vector = torch.tensor([[100], [200]])  # Shape: (2, 1)\n",
    "\n",
    "print(f\"Matrix:\\n{matrix}\")\n",
    "print(f\"Matrix shape: {matrix.shape}\")\n",
    "print()\n",
    "\n",
    "print(f\"Row vector: {row_vector}\")\n",
    "print(f\"Row vector shape: {row_vector.shape}\")\n",
    "print(f\"Matrix + row vector:\\n{matrix + row_vector}\")\n",
    "print(\"Row vector gets 'copied' to each row of the matrix!\")\n",
    "print()\n",
    "\n",
    "print(f\"Column vector:\\n{col_vector}\")\n",
    "print(f\"Column vector shape: {col_vector.shape}\")\n",
    "print(f\"Matrix + column vector:\\n{matrix + col_vector}\")\n",
    "print(\"Column vector gets 'copied' to each column of the matrix!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5dcd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's understand the broadcasting rules step by step\n",
    "print(\"=== The Broadcasting Algorithm ===\")\n",
    "\n",
    "def check_broadcast_compatibility(shape1, shape2):\n",
    "    \"\"\"Show step-by-step how PyTorch decides if shapes can broadcast\"\"\"\n",
    "    print(f\"Shape 1: {shape1}\")\n",
    "    print(f\"Shape 2: {shape2}\")\n",
    "    \n",
    "    # PyTorch compares dimensions from RIGHT to LEFT\n",
    "    max_dims = max(len(shape1), len(shape2))\n",
    "    shape1_padded = [1] * (max_dims - len(shape1)) + list(shape1)\n",
    "    shape2_padded = [1] * (max_dims - len(shape2)) + list(shape2)\n",
    "    \n",
    "    print(f\"After padding: {shape1_padded} vs {shape2_padded}\")\n",
    "    \n",
    "    result_shape = []\n",
    "    compatible = True\n",
    "    \n",
    "    for i in range(max_dims):\n",
    "        dim1, dim2 = shape1_padded[i], shape2_padded[i]\n",
    "        print(f\"Dimension {i}: {dim1} vs {dim2}\", end=\" -> \")\n",
    "        \n",
    "        if dim1 == dim2:\n",
    "            result_shape.append(dim1)\n",
    "            print(f\"Same size: {dim1}\")\n",
    "        elif dim1 == 1:\n",
    "            result_shape.append(dim2)\n",
    "            print(f\"Broadcast dim1: {dim2}\")\n",
    "        elif dim2 == 1:\n",
    "            result_shape.append(dim1)\n",
    "            print(f\"Broadcast dim2: {dim1}\")\n",
    "        else:\n",
    "            print(\"INCOMPATIBLE!\")\n",
    "            compatible = False\n",
    "            break\n",
    "    \n",
    "    if compatible:\n",
    "        print(f\"‚úÖ Result shape: {result_shape}\")\n",
    "    else:\n",
    "        print(\"‚ùå Cannot broadcast!\")\n",
    "    print()\n",
    "    return compatible\n",
    "\n",
    "# Test some examples\n",
    "check_broadcast_compatibility((2, 3), (3,))      # Works\n",
    "check_broadcast_compatibility((2, 3), (2, 1))    # Works  \n",
    "check_broadcast_compatibility((2, 3), (2, 4))    # Fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7f936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see broadcasting in action with real examples\n",
    "print(\"=== Hands-on Broadcasting Examples ===\")\n",
    "\n",
    "# Example 1: Adding bias to each row of a matrix  \n",
    "matrix = torch.randn(3, 4)\n",
    "row_bias = torch.tensor([1, 2, 3, 4])  # Shape: (4,)\n",
    "\n",
    "print(\"Matrix (3x4):\")\n",
    "print(matrix)\n",
    "print(f\"\\nRow bias (4,): {row_bias}\")\n",
    "print(f\"\\nMatrix + row_bias (broadcasts to 3x4):\")\n",
    "print(matrix + row_bias)\n",
    "print(\"The bias gets added to EVERY row!\")\n",
    "print()\n",
    "\n",
    "# Example 2: Adding bias to each column of a matrix\n",
    "col_bias = torch.tensor([[10], [20], [30]])  # Shape: (3, 1)\n",
    "print(f\"Column bias (3x1):\\n{col_bias}\")\n",
    "print(f\"\\nMatrix + col_bias (broadcasts to 3x4):\")\n",
    "print(matrix + col_bias)\n",
    "print(\"The bias gets added to EVERY column!\")\n",
    "print()\n",
    "\n",
    "# Example 3: Element-wise operations with broadcasting\n",
    "A = torch.tensor([[1, 2], [3, 4]])  # (2, 2)\n",
    "B = torch.tensor([10, 100])         # (2,)\n",
    "print(f\"A (2x2):\\n{A}\")\n",
    "print(f\"B (2,): {B}\")\n",
    "print(f\"A * B (element-wise, broadcasts):\\n{A * B}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02450212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common broadcasting mistakes and how to debug them\n",
    "print(\"=== Common Broadcasting Pitfalls ===\")\n",
    "\n",
    "# Mistake 1: Incompatible shapes\n",
    "try:\n",
    "    a = torch.tensor([[1, 2, 3]])        # (1, 3)\n",
    "    b = torch.tensor([[1], [2]])         # (2, 1) \n",
    "    print(f\"a.shape: {a.shape}, b.shape: {b.shape}\")\n",
    "    result = a + b  # This actually works! (1,3) + (2,1) -> (2,3)\n",
    "    print(f\"Success! Result shape: {result.shape}\")\n",
    "    print(f\"Result:\\n{result}\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "print()\n",
    "\n",
    "# Mistake 2: Really incompatible shapes\n",
    "try:\n",
    "    a = torch.tensor([[1, 2, 3], [4, 5, 6]])  # (2, 3)\n",
    "    b = torch.tensor([[1, 2], [3, 4]])         # (2, 2)\n",
    "    print(f\"a.shape: {a.shape}, b.shape: {b.shape}\")\n",
    "    result = a + b  # This will fail!\n",
    "except RuntimeError as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "print()\n",
    "\n",
    "# How to debug: Use unsqueeze to add dimensions\n",
    "print(\"=== Debugging with .unsqueeze() ===\")\n",
    "vec = torch.tensor([1, 2, 3])  # Shape: (3,)\n",
    "print(f\"Original vector shape: {vec.shape}\")\n",
    "print(f\"After unsqueeze(0): {vec.unsqueeze(0).shape}\")  # (1, 3)\n",
    "print(f\"After unsqueeze(1): {vec.unsqueeze(1).shape}\")  # (3, 1)\n",
    "print(\"Use unsqueeze to add dimensions of size 1 for broadcasting!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae95325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced broadcasting: Working with higher dimensions\n",
    "print(\"=== Advanced Broadcasting: 3D+ Tensors ===\")\n",
    "\n",
    "# Simulate a batch of images: (batch, height, width)\n",
    "batch_of_images = torch.randn(2, 3, 4)  # 2 images, 3x4 each\n",
    "print(f\"Batch of images shape: {batch_of_images.shape}\")\n",
    "\n",
    "# Add different bias to each image in the batch\n",
    "batch_bias = torch.tensor([[[1]], [[2]]])  # Shape: (2, 1, 1)\n",
    "print(f\"Batch bias shape: {batch_bias.shape}\")\n",
    "result = batch_of_images + batch_bias\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "print(\"Each image gets a different bias value!\")\n",
    "print()\n",
    "\n",
    "# Add different bias to each row of every image  \n",
    "row_bias = torch.tensor([10, 20, 30])  # Shape: (3,)\n",
    "print(f\"Row bias shape: {row_bias.shape}\")\n",
    "result = batch_of_images + row_bias.unsqueeze(1)  # Make it (3, 1)\n",
    "print(f\"After unsqueeze(1): {row_bias.unsqueeze(1).shape}\")\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "print(\"Every row in every image gets different bias!\")\n",
    "print()\n",
    "\n",
    "# The power of broadcasting: Complex operations in one line\n",
    "print(\"=== Broadcasting enables complex operations ===\")\n",
    "# Normalize each image by its mean (broadcasting magic!)\n",
    "means = batch_of_images.mean(dim=(1, 2), keepdim=True)  # (2, 1, 1)\n",
    "normalized = batch_of_images - means\n",
    "print(f\"Mean shape: {means.shape}\")\n",
    "print(f\"Normalized shape: {normalized.shape}\")\n",
    "print(\"Each image normalized by its own mean - all in one operation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6d7f0c",
   "metadata": {},
   "source": [
    "## üß™ Broadcasting Playground\n",
    "\n",
    "Now it's your turn! Try these experiments to master broadcasting:\n",
    "\n",
    "1. **Shape Detective**: Create tensors with shapes `(3, 1)` and `(1, 4)`. What happens when you add them?\n",
    "\n",
    "2. **Bias Challenge**: Create a `(5, 3)` matrix and add a different bias to each column\n",
    "\n",
    "3. **Batch Normalization**: Create a `(10, 20, 30)` tensor and subtract the mean of each `(20, 30)` slice\n",
    "\n",
    "4. **Error Explorer**: Try operations that will fail and see what PyTorch tells you\n",
    "\n",
    "5. **Dimension Engineering**: Use `unsqueeze()`, `squeeze()`, and `reshape()` to make incompatible shapes work together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2700ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ YOUR BROADCASTING EXPERIMENTS GO HERE!\n",
    "\n",
    "print(\"=== Experiment 1: Shape Detective ===\")\n",
    "# Try: (3, 1) + (1, 4) = ?\n",
    "a = torch.tensor([[1], [2], [3]])  # (3, 1)\n",
    "b = torch.tensor([[10, 20, 30, 40]])  # (1, 4)\n",
    "# Your code here:\n",
    "\n",
    "\n",
    "print(\"\\n=== Experiment 2: Column Bias Challenge ===\") \n",
    "# Create (5, 3) matrix, add different bias to each column\n",
    "matrix = torch.randn(5, 3)\n",
    "# Your code here:\n",
    "\n",
    "\n",
    "print(\"\\n=== Experiment 3: Batch Normalization ===\")\n",
    "# Create (10, 20, 30) tensor, subtract mean of each (20, 30) slice\n",
    "data = torch.randn(10, 20, 30)\n",
    "# Your code here:\n",
    "\n",
    "\n",
    "print(\"\\n=== Experiment 4: Your Creative Broadcasting ===\")\n",
    "# Try your own broadcasting experiment!\n",
    "# Your code here:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.17",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
